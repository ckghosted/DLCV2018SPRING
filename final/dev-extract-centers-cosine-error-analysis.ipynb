{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='6'\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from VGG16_GAP import VGG16_GAP\n",
    "# from VGG16_flatten import VGG16_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as imageio\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from progress.bar import Bar\n",
    "# from ipywidgets import IntProgress\n",
    "# from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/cclin/ntu/dlcv2018/DLCV2018SPRING/final/label_dict.pkl', 'rb') as f:\n",
    "    y_dict = pickle.load(f)\n",
    "\n",
    "with open('/home/cclin/ntu/dlcv2018/DLCV2018SPRING/final/inv_label_dict.pkl', 'rb') as f:\n",
    "    inv_y_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('save/inv_label_dict.pkl', 'rb') as f:\n",
    "#     inv_y_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOME_DIR = \"/data/put_data/cclin/ntu/dlcv2018/final/\"\n",
    "TRAIN_DIR = HOME_DIR+\"dlcv_final_2_dataset/train/\"\n",
    "VALID_DIR = HOME_DIR+\"dlcv_final_2_dataset/val/\"\n",
    "TEST_DIR = HOME_DIR+\"dlcv_final_2_dataset/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = pd.read_csv(HOME_DIR+\"dlcv_final_2_dataset/train_id.txt\", header=None,sep=\" \", names=[\"img\", \"id\"])\n",
    "dvalid = pd.read_csv(HOME_DIR+\"dlcv_final_2_dataset/val_id.txt\", header=None,sep=\" \", names=[\"img\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list = list(TRAIN_DIR+dtrain.img)\n",
    "valid_list = list(VALID_DIR+dvalid.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_list = list()\n",
    "for root, subdir, files in os.walk(TEST_DIR):\n",
    "    for file in sorted(files):\n",
    "        if '.jpg' in file:\n",
    "            test_list.append(os.path.join(TEST_DIR, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readImgList(file_list):\n",
    "    images = list()\n",
    "    for i, file in enumerate(file_list):\n",
    "        print(i, end=\"\\r\")\n",
    "        img = imageio.imread(file)\n",
    "        img = img.astype(int)\n",
    "        images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformLabel(id_list, y_dict):\n",
    "    label = list()\n",
    "    for uid in list(id_list):\n",
    "        label.append(y_dict[uid])\n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(class_numbers, num_classes):\n",
    "    return np.eye(num_classes, dtype=float)[class_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v,f) in zip(global_vars, is_not_initialized) if not f]\n",
    "    if len(not_initialized_vars): \n",
    "            sess.run(tf.variables_initializer(not_initialized_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (56475, 218, 178, 3)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = readImgList(train_list)\n",
    "print(\"train:\", Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: (7211, 218, 178, 3)\n"
     ]
    }
   ],
   "source": [
    "Xvalid = readImgList(valid_list)\n",
    "print(\"valid:\", Xvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: (7152, 218, 178, 3)\n"
     ]
    }
   ],
   "source": [
    "Xtest = readImgList(test_list)\n",
    "print(\"valid:\", Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain = transformLabel(list(dtrain.id), y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yvalid = transformLabel(list(dvalid.id), y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ytrain = one_hot_encoding(ytrain, len(y_dict))\n",
    "Yvalid = one_hot_encoding(yvalid, len(y_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scope_name = \"Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VGG16_GAP(scope_name=scope_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAG_save_dir = \"/data/put_data/cmchang/DLCV_final/newCL_v2_lambda-1e-1_dynamic_gap_L5_v3_rescale0-1_save_linear/\"\n",
    "FLAG_init_from = FLAG_save_dir + \"para_dict.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build model started\n",
      "npy file loaded\n",
      "build model finished: 0s\n"
     ]
    }
   ],
   "source": [
    "model.build(vgg16_npy_path=FLAG_init_from,\n",
    "            shape=Xtrain.shape[1:],\n",
    "            classes=len(y_dict),\n",
    "            conv_pre_training=True,\n",
    "            fc_pre_training=True,\n",
    "            new_bn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP under test: [1.]\n",
      "[None, 218, 178, 3]\n",
      "[None, 218, 178, 32]\n",
      "AFTER [None, 218, 178, 32]\n",
      "[None, 109, 89, 47]\n",
      "AFTER [None, 109, 89, 47]\n",
      "[None, 109, 89, 63]\n",
      "AFTER [None, 109, 89, 63]\n",
      "[None, 55, 45, 98]\n",
      "AFTER [None, 55, 45, 98]\n",
      "[None, 55, 45, 134]\n",
      "AFTER [None, 55, 45, 134]\n",
      "[None, 55, 45, 147]\n",
      "AFTER [None, 55, 45, 147]\n",
      "[None, 28, 23, 153]\n",
      "AFTER [None, 28, 23, 153]\n",
      "[None, 28, 23, 209]\n",
      "AFTER [None, 28, 23, 209]\n",
      "[None, 28, 23, 181]\n",
      "AFTER [None, 28, 23, 181]\n",
      "[None, 14, 12, 177]\n",
      "AFTER [None, 14, 12, 177]\n",
      "[None, 14, 12, 180]\n",
      "AFTER [None, 14, 12, 180]\n",
      "[None, 14, 12, 230]\n",
      "AFTER [None, 14, 12, 230]\n",
      "Set dp operations finished: 0s\n"
     ]
    }
   ],
   "source": [
    "dp = [1.0]\n",
    "model.set_idp_operation(dp=dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_number_params(para_dict):\n",
    "    n = 0\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            continue\n",
    "        elif 'bn_variance' in k:\n",
    "            continue\n",
    "        elif 'gamma' in k:\n",
    "            continue\n",
    "        elif 'beta' in k:\n",
    "            continue\n",
    "        elif 'conv' in k or 'fc' in k:\n",
    "            n += get_params_shape(v[0].shape.as_list())\n",
    "            n += get_params_shape(v[1].shape.as_list())\n",
    "    return n\n",
    "\n",
    "def get_params_shape(shape):\n",
    "    n = 1\n",
    "    for dim in shape:\n",
    "        n = n*dim\n",
    "    return n\n",
    "\n",
    "def count_flops(para_dict, net_shape, input_shape=(3, 218, 178)):\n",
    "    # Format:(channels, rows,cols)\n",
    "    total_flops_per_layer = 0\n",
    "    input_count = 0\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            continue\n",
    "        elif 'bn_variance' in k:\n",
    "            continue\n",
    "        elif 'gamma' in k:\n",
    "            continue\n",
    "        elif 'beta' in k:\n",
    "            continue\n",
    "        elif 'fc' in k:\n",
    "            continue\n",
    "        elif 'conv' in k:\n",
    "            conv_filter = v[0].shape.as_list()[3::-1] # (64 ,3 ,3 ,3)  # Format: (num_filters, channels, rows, cols)\n",
    "            stride = 1\n",
    "            padding = 1\n",
    "\n",
    "            if conv_filter[1] == 0:\n",
    "                n = conv_filter[2] * conv_filter[3] # vector_length\n",
    "            else:\n",
    "                n = conv_filter[1] * conv_filter[2] * conv_filter[3]  # vector_length\n",
    "\n",
    "            flops_per_instance = n + ( n -1)    # general defination for number of flops (n: multiplications and n-1: additions)\n",
    "\n",
    "            num_instances_per_filter = (( input_shape[1] - conv_filter[2] + 2 * padding) / stride) + 1  # for rows\n",
    "            num_instances_per_filter *= ((input_shape[2] - conv_filter[3] + 2 * padding) / stride) + 1  # multiplying with cols\n",
    "\n",
    "            flops_per_filter = num_instances_per_filter * flops_per_instance\n",
    "            total_flops_per_layer += flops_per_filter * conv_filter[0]  # multiply with number of filters\n",
    "\n",
    "            total_flops_per_layer += conv_filter[0] * input_shape[1] * input_shape[2] # bias\n",
    "\n",
    "            input_shape = net_shape[input_count].as_list()[3:0:-1]\n",
    "            input_count +=1\n",
    "\n",
    "    total_flops_per_layer += net_shape[-1].as_list()[1] *2360*2\n",
    "    return total_flops_per_layer\n",
    "\n",
    "def countFlopsParas(net):\n",
    "    total_flops = count_flops(net.para_dict, net.net_shape)\n",
    "    if total_flops / 1e9 > 1:   # for Giga Flops\n",
    "        print(total_flops/ 1e9 ,'{}'.format('GFlops'))\n",
    "    else:\n",
    "        print(total_flops / 1e6 ,'{}'.format('MFlops'))\n",
    "\n",
    "    total_params = count_number_params(net.para_dict)\n",
    "\n",
    "    if total_params / 1e9 > 1:   # for Giga Flops\n",
    "        print(total_params/ 1e9 ,'{}'.format('G'))\n",
    "    else:\n",
    "        print(total_params / 1e6 ,'{}'.format('M'))\n",
    "    \n",
    "    return total_flops, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.875544996 GFlops\n",
      "4.048755 M\n",
      "Flops: 6875.544996 M, Paras: 4.048755 M\n"
     ]
    }
   ],
   "source": [
    "flops, params = countFlopsParas(model)\n",
    "FLAG_flops_M = flops/1e6\n",
    "FLAG_params_M = params/1e6\n",
    "print(\"Flops: %3f M, Paras: %3f M\" % (flops/1e6, params/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "282\n",
      "36\n",
      "35\r"
     ]
    }
   ],
   "source": [
    "# extract features\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.global_variables())\n",
    "    print(\"Initialized\")\n",
    "    output_train = []\n",
    "    output_valid = []\n",
    "    output_test = []\n",
    "    for i in range(int(Xtrain.shape[0]/200+1)):\n",
    "        print(i, end=\"\\r\")\n",
    "        st = i*200\n",
    "        ed = min((i+1)*200, Xtrain.shape[0])\n",
    "        prob = sess.run(model.features, feed_dict={model.x: Xtrain[st:ed,:], \n",
    "                                                    model.is_train: False})\n",
    "        output_train.append(prob)\n",
    "    print()\n",
    "    \n",
    "    for i in range(int(Xvalid.shape[0]/200+1)):\n",
    "        print(i, end=\"\\r\")\n",
    "        st = i*200\n",
    "        ed = min((i+1)*200, Xvalid.shape[0])\n",
    "        prob = sess.run(model.features, feed_dict={model.x: Xvalid[st:ed,:], \n",
    "                                                    model.is_train: False})\n",
    "        output_valid.append(prob)\n",
    "    print()\n",
    "    \n",
    "    for i in range(int(Xtest.shape[0]/200+1)):\n",
    "        print(i, end=\"\\r\")\n",
    "        st = i*200\n",
    "        ed = min((i+1)*200, Xtest.shape[0])\n",
    "        prob = sess.run(model.features, feed_dict={model.x: Xtest[st:ed,:], \n",
    "                                                    model.is_train: False})\n",
    "        output_test.append(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute center and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'data', 'put_data', 'cmchang', 'DLCV_final', 'newCL_v2_lambda-1e-1_dynamic_gap_L5_v3_rescale0-1_save_linear', '']\n",
      "newCL_v2_lambda-1e-1_dynamic_gap_L5_v3_rescale0-1_save_linear\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "\n",
    "print(re.split(pattern='\\/', string=FLAG_save_dir))\n",
    "basic_model_name = re.split(pattern='\\/', string=FLAG_save_dir)[-2]\n",
    "print(basic_model_name)\n",
    "\n",
    "saved_path = os.path.join('/data/put_data/cclin/ntu/dlcv2018/final/results', basic_model_name)\n",
    "if not os.path.exists(saved_path):\n",
    "    os.makedirs(saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56475, 423)\n"
     ]
    }
   ],
   "source": [
    "EX_train = np.concatenate(output_train,)\n",
    "print(EX_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7211, 423)\n"
     ]
    }
   ],
   "source": [
    "EX_valid = np.concatenate(output_valid,)\n",
    "print(EX_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7152, 423)\n"
     ]
    }
   ],
   "source": [
    "EX_test = np.concatenate(output_test,)\n",
    "print(EX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(os.path.join(saved_path, 'EX_train.npy'), EX_train)\n",
    "np.save(os.path.join(saved_path, 'EX_valid.npy'), EX_valid)\n",
    "np.save(os.path.join(saved_path, 'EX_test.npy'), EX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers = np.zeros((len(y_dict), EX_train.shape[1]))\n",
    "for i in range(len(y_dict)):\n",
    "    centers[i,:] = np.mean(EX_train[ytrain==i,:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2360, 423)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(arr=centers,file=FLAG_save_dir+\"centers.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7211, 2360)\n",
      "(7211,)\n"
     ]
    }
   ],
   "source": [
    "cos_sim = cosine_similarity(EX_valid, centers)\n",
    "print(cos_sim.shape)\n",
    "pred_valid = np.argmax(cos_sim, axis=1)\n",
    "print(pred_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8374705311329913"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(list(yvalid), list(pred_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63686, 423)\n"
     ]
    }
   ],
   "source": [
    "EX_all = np.concatenate((EX_train, EX_valid))\n",
    "print(EX_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63686,)\n"
     ]
    }
   ],
   "source": [
    "Y = np.concatenate([ytrain, yvalid])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers_all = np.zeros((len(y_dict), EX_all.shape[1]))\n",
    "for i in range(len(y_dict)):\n",
    "    centers_all[i,:] = np.mean(EX_all[Y==i,:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2360, 423)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7152, 2360)\n",
      "(7152,)\n"
     ]
    }
   ],
   "source": [
    "cos_sim = cosine_similarity(EX_test, centers_all)\n",
    "print(cos_sim.shape)\n",
    "pred_test = np.argmax(cos_sim, axis=1)\n",
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_id = list()\n",
    "for pred in pred_test:\n",
    "    final_id.append(inv_y_dict[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doutput = pd.DataFrame({'id':np.arange(len(final_id))+1, 'ans':final_id}, columns=['id','ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_pred_val83_newCL_v2_lambda-1e-1_dynamic_gap_L5_v3_rescale0-1_save_linear.csv\n"
     ]
    }
   ],
   "source": [
    "output_name = \"cos_pred_val83_\" + basic_model_name + \".csv\"\n",
    "print(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doutput.to_csv(output_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backup: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "# neigh.fit(centers, np.arange(len(y_dict)))\n",
    "# pred_valid = neigh.predict(EX_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import compress\n",
    "from scipy.stats.stats import pearsonr\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (0) accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/function_base.py:1128: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class = []\n",
    "for i in range(len(y_dict)):\n",
    "    accuracy_per_class.append(accuracy_score(list(yvalid[yvalid==i]), list(pred_valid[yvalid==i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7wAAAF3CAYAAACG80dpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgAAMCSBFwAAgCEJvAAAAAzp/wMhx4Xas35RHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ef3c4065b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## remove nan accuracy\n",
    "accuracy_per_class_ = list(compress(accuracy_per_class, list(~np.isnan(accuracy_per_class))))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "ax.hist(accuracy_per_class_, bins=50)\n",
    "ax.set_title('')\n",
    "ax.set_xlabel('per class accuracy')\n",
    "ax.set_ylabel('frequency')\n",
    "plt.show()\n",
    "# fig.savefig(dir_name+'/outputs/ave_generated_vs_real.png')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) accuracy vs. number of training/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train_file = []\n",
    "n_valid_file = []\n",
    "for i in range(len(accuracy_per_class)):\n",
    "    dtrain_temp = dtrain.query('id == '+str(inv_y_dict[i]))\n",
    "    train_list_temp = list(TRAIN_DIR+dtrain_temp.img)\n",
    "    n_train_file.append(len(train_list_temp))\n",
    "    dvalid_temp = dvalid.query('id == '+str(inv_y_dict[i]))\n",
    "    valid_list_temp = list(VALID_DIR+dvalid_temp.img)\n",
    "    n_valid_file.append(len(valid_list_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## remove rows with nan accuracy\n",
    "n_train_file_ = list(compress(n_train_file, list(~np.isnan(accuracy_per_class))))\n",
    "n_valid_file_ = list(compress(n_valid_file, list(~np.isnan(accuracy_per_class))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02904605653881193, 0.16672475141733487)\n",
      "(0.004019039117950236, 0.8482936476169467)\n"
     ]
    }
   ],
   "source": [
    "## compute correlation between number\n",
    "print(pearsonr(n_train_file_, accuracy_per_class_))\n",
    "print(pearsonr(n_valid_file_, accuracy_per_class_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) copy images of bad classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 30, label = 220, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 1\n",
      "index = 59, label = 433, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 2\n",
      "index = 95, label = 844, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 1\n",
      "index = 118, label = 997, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 123, label = 1018, valid accuracy = 0.0000, n.train.file = 28, n.valid.file = 1\n",
      "index = 141, label = 1066, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 143, label = 1089, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 173, label = 1221, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 2\n",
      "index = 203, label = 1322, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 250, label = 1470, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 289, label = 1589, valid accuracy = 0.0000, n.train.file = 29, n.valid.file = 1\n",
      "index = 293, label = 1603, valid accuracy = 0.0000, n.train.file = 28, n.valid.file = 1\n",
      "index = 370, label = 1903, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 454, label = 2173, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 3\n",
      "index = 473, label = 2242, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 557, label = 2613, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 585, label = 2867, valid accuracy = 0.0000, n.train.file = 20, n.valid.file = 3\n",
      "index = 680, label = 3214, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 1\n",
      "index = 736, label = 3490, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 754, label = 3614, valid accuracy = 0.0000, n.train.file = 28, n.valid.file = 2\n",
      "index = 764, label = 3670, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 2\n",
      "index = 767, label = 3696, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 796, label = 3853, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 3\n",
      "index = 805, label = 3882, valid accuracy = 0.0000, n.train.file = 19, n.valid.file = 5\n",
      "index = 871, label = 4161, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 2\n",
      "index = 897, label = 4245, valid accuracy = 0.0000, n.train.file = 21, n.valid.file = 3\n",
      "index = 919, label = 4306, valid accuracy = 0.0000, n.train.file = 28, n.valid.file = 1\n",
      "index = 922, label = 4310, valid accuracy = 0.0000, n.train.file = 21, n.valid.file = 1\n",
      "index = 961, label = 4441, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 2\n",
      "index = 968, label = 4460, valid accuracy = 0.0000, n.train.file = 20, n.valid.file = 3\n",
      "index = 995, label = 4558, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 2\n",
      "index = 1004, label = 4582, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 3\n",
      "index = 1011, label = 4609, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 2\n",
      "index = 1023, label = 4652, valid accuracy = 0.0000, n.train.file = 21, n.valid.file = 1\n",
      "index = 1094, label = 4910, valid accuracy = 0.0000, n.train.file = 22, n.valid.file = 1\n",
      "index = 1121, label = 4976, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 1\n",
      "index = 1137, label = 5024, valid accuracy = 0.0000, n.train.file = 22, n.valid.file = 3\n",
      "index = 1140, label = 5028, valid accuracy = 0.0000, n.train.file = 23, n.valid.file = 3\n",
      "index = 1150, label = 5071, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 1\n",
      "index = 1167, label = 5125, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 1\n",
      "index = 1291, label = 5433, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 2\n",
      "index = 1295, label = 5449, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 1\n",
      "index = 1335, label = 5563, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 1\n",
      "index = 1353, label = 5663, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 2\n",
      "index = 1379, label = 5786, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 2\n",
      "index = 1403, label = 5922, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 1\n",
      "index = 1443, label = 6100, valid accuracy = 0.0000, n.train.file = 20, n.valid.file = 2\n",
      "index = 1474, label = 6183, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 1475, label = 6184, valid accuracy = 0.0000, n.train.file = 27, n.valid.file = 2\n",
      "index = 1508, label = 6288, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 3\n",
      "index = 1544, label = 6364, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 1564, label = 6415, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 2\n",
      "index = 1648, label = 6725, valid accuracy = 0.0000, n.train.file = 23, n.valid.file = 2\n",
      "index = 1649, label = 6726, valid accuracy = 0.0000, n.train.file = 22, n.valid.file = 2\n",
      "index = 1713, label = 7081, valid accuracy = 0.0000, n.train.file = 27, n.valid.file = 1\n",
      "index = 1728, label = 7142, valid accuracy = 0.0000, n.train.file = 27, n.valid.file = 1\n",
      "index = 1812, label = 7427, valid accuracy = 0.0000, n.train.file = 27, n.valid.file = 2\n",
      "index = 1831, label = 7541, valid accuracy = 0.0000, n.train.file = 28, n.valid.file = 1\n",
      "index = 1841, label = 7613, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 1\n",
      "index = 1856, label = 7768, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 3\n",
      "index = 1947, label = 8514, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 1\n",
      "index = 1951, label = 8520, valid accuracy = 0.0000, n.train.file = 28, n.valid.file = 1\n",
      "index = 1969, label = 8597, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 1994, label = 8663, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 2\n",
      "index = 2076, label = 8875, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 2102, label = 8940, valid accuracy = 0.0000, n.train.file = 27, n.valid.file = 1\n",
      "index = 2109, label = 8951, valid accuracy = 0.0000, n.train.file = 27, n.valid.file = 2\n",
      "index = 2115, label = 8963, valid accuracy = 0.0000, n.train.file = 20, n.valid.file = 3\n",
      "index = 2126, label = 8985, valid accuracy = 0.0000, n.train.file = 27, n.valid.file = 1\n",
      "index = 2173, label = 9152, valid accuracy = 0.0000, n.train.file = 23, n.valid.file = 1\n",
      "index = 2240, label = 9729, valid accuracy = 0.0000, n.train.file = 27, n.valid.file = 1\n",
      "index = 2248, label = 9758, valid accuracy = 0.0000, n.train.file = 27, n.valid.file = 1\n",
      "index = 2252, label = 9787, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 2\n",
      "index = 2255, label = 9794, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 2\n",
      "index = 2274, label = 9902, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 2\n",
      "index = 2282, label = 9926, valid accuracy = 0.0000, n.train.file = 28, n.valid.file = 1\n",
      "index = 2285, label = 9935, valid accuracy = 0.0000, n.train.file = 28, n.valid.file = 1\n",
      "index = 2293, label = 9979, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 1\n",
      "index = 2327, label = 10080, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 2\n",
      "index = 2331, label = 10086, valid accuracy = 0.0000, n.train.file = 24, n.valid.file = 1\n",
      "index = 2338, label = 10102, valid accuracy = 0.0000, n.train.file = 26, n.valid.file = 1\n",
      "index = 2347, label = 10143, valid accuracy = 0.0000, n.train.file = 27, n.valid.file = 1\n",
      "index = 2350, label = 10156, valid accuracy = 0.0000, n.train.file = 25, n.valid.file = 1\n",
      "count = 83\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "acc_threshold = 0.2\n",
    "\n",
    "bad_path = os.path.join(saved_path, 'bad')\n",
    "if not os.path.exists(bad_path):\n",
    "    os.makedirs(bad_path)\n",
    "\n",
    "for i in range(len(accuracy_per_class)):\n",
    "    if accuracy_per_class[i] < acc_threshold:\n",
    "        count += 1\n",
    "        bad_class_path = os.path.join(bad_path, str(inv_y_dict[i]))\n",
    "        if not os.path.exists(bad_class_path):\n",
    "            os.makedirs(bad_class_path)\n",
    "            bad_train_path = os.path.join(bad_class_path, 'train')\n",
    "            os.makedirs(bad_train_path)\n",
    "            bad_valid_path = os.path.join(bad_class_path, 'valid')\n",
    "            os.makedirs(bad_valid_path)\n",
    "        dtrain_temp = dtrain.query('id == '+str(inv_y_dict[i]))\n",
    "        train_list_temp = list(TRAIN_DIR+dtrain_temp.img)\n",
    "        for img in train_list_temp:\n",
    "            copyfile(img, os.path.join(bad_train_path, os.path.basename(img)))\n",
    "        dvalid_temp = dvalid.query('id == '+str(inv_y_dict[i]))\n",
    "        valid_list_temp = list(VALID_DIR+dvalid_temp.img)\n",
    "        for img in valid_list_temp:\n",
    "            copyfile(img, os.path.join(bad_valid_path, os.path.basename(img)))\n",
    "        print('index = %d, label = %d, valid accuracy = %.4f, n.train.file = %d, n.valid.file = %d' % \\\n",
    "              (i, inv_y_dict[i], accuracy_per_class[i], len(train_list_temp), len(valid_list_temp)))\n",
    "print('count = %d' % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
