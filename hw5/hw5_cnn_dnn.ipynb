{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model import EXTRACTOR, DNN\n",
    "import os, re, glob\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import skimage\n",
    "import skimage.io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_path_train = '/data/put_data/cclin/ntu/dlcv2018/hw5/HW5_data/TrimmedVideos/video/train'\n",
    "label_file_train = '/data/put_data/cclin/ntu/dlcv2018/hw5/HW5_data/TrimmedVideos/label/gt_train.csv'\n",
    "feature_path_train = '/data/put_data/cclin/ntu/dlcv2018/hw5/cnn_features_train.npy'\n",
    "\n",
    "video_path_valid = '/data/put_data/cclin/ntu/dlcv2018/hw5/HW5_data/TrimmedVideos/video/valid'\n",
    "label_file_valid = '/data/put_data/cclin/ntu/dlcv2018/hw5/HW5_data/TrimmedVideos/label/gt_valid.csv'\n",
    "feature_path_valid = '/data/put_data/cclin/ntu/dlcv2018/hw5/cnn_features_valid.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract CNN-based features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) extract training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16.npy loaded\n",
      "RGB to BGR\n",
      "build model started\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    net = EXTRACTOR(sess)\n",
    "    net.build_vgg16()\n",
    "    res = net.extract(video_path=video_path_train,\n",
    "                      label_file=label_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "3236\n",
      "<class 'numpy.ndarray'>\n",
      "(4, 40960)\n",
      "[[0.        0.        0.        ... 0.        0.        5.4289293]\n",
      " [0.        0.        0.        ... 0.        4.7238235 0.       ]\n",
      " [0.        0.        0.        ... 0.        4.732338  5.7481074]\n",
      " [0.        0.        0.        ... 0.        0.        1.9387643]]\n"
     ]
    }
   ],
   "source": [
    "## debug\n",
    "print(type(res))\n",
    "print(len(res))\n",
    "print(type(res[0]))\n",
    "print(res[0].shape)\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(feature_path_train, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) extract validation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16.npy loaded\n",
      "RGB to BGR\n",
      "build model started\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    net = EXTRACTOR(sess)\n",
    "    net.build_vgg16()\n",
    "    res = net.extract(video_path=video_path_valid,\n",
    "                      label_file=label_file_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(feature_path_valid, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Train the discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_name = 'cnn_dnn_2048_512_11_bs32_lr5e5_ep50'\n",
    "bsize = 32\n",
    "learning_rate = 5e-5\n",
    "num_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 2.016451, valid loss: 1.770868, train accuracy: 0.316483, valid accuracy: 0.411397\n",
      "Epoch: 2, train loss: 1.016238, valid loss: 1.646856, train accuracy: 0.855392, valid accuracy: 0.423529\n",
      "stopping_step = 0\n",
      "Epoch: 3, train loss: 0.559776, valid loss: 1.607248, train accuracy: 0.969975, valid accuracy: 0.434559\n",
      "stopping_step = 0\n",
      "Epoch: 4, train loss: 0.315284, valid loss: 1.592499, train accuracy: 0.996630, valid accuracy: 0.443750\n",
      "stopping_step = 0\n",
      "Epoch: 5, train loss: 0.189573, valid loss: 1.588220, train accuracy: 0.998775, valid accuracy: 0.461029\n",
      "stopping_step = 0\n",
      "Epoch: 6, train loss: 0.123662, valid loss: 1.588453, train accuracy: 0.999694, valid accuracy: 0.445588\n",
      "stopping_step = 1\n",
      "Epoch: 7, train loss: 0.086680, valid loss: 1.592129, train accuracy: 1.000000, valid accuracy: 0.449265\n",
      "stopping_step = 2\n",
      "Epoch: 8, train loss: 0.064186, valid loss: 1.595355, train accuracy: 1.000000, valid accuracy: 0.449265\n",
      "stopping_step = 3\n",
      "Epoch: 9, train loss: 0.049568, valid loss: 1.600980, train accuracy: 1.000000, valid accuracy: 0.458456\n",
      "stopping_step = 4\n",
      "Epoch: 10, train loss: 0.039504, valid loss: 1.605431, train accuracy: 1.000000, valid accuracy: 0.470221\n",
      "stopping_step = 5\n",
      "Epoch: 11, train loss: 0.032247, valid loss: 1.610710, train accuracy: 1.000000, valid accuracy: 0.470221\n",
      "stopping_step = 6\n",
      "Epoch: 12, train loss: 0.026838, valid loss: 1.616455, train accuracy: 1.000000, valid accuracy: 0.473897\n",
      "stopping_step = 7\n",
      "Epoch: 13, train loss: 0.022688, valid loss: 1.621528, train accuracy: 1.000000, valid accuracy: 0.473897\n",
      "stopping_step = 8\n",
      "Epoch: 14, train loss: 0.019436, valid loss: 1.627175, train accuracy: 1.000000, valid accuracy: 0.477574\n",
      "stopping_step = 9\n",
      "Epoch: 15, train loss: 0.016831, valid loss: 1.631982, train accuracy: 1.000000, valid accuracy: 0.479412\n",
      "stopping_step = 10\n",
      "stopping_step >= patience (10), stop training\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    net = DNN(sess,\n",
    "              model_name=dir_name)\n",
    "    net.build_model()\n",
    "    results = net.train(feature_path_train=feature_path_train,\n",
    "                        bsize=bsize,\n",
    "                        learning_rate=learning_rate,\n",
    "                        num_epoch=num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('/data/put_data/cclin/ntu/dlcv2018/hw5/results', dir_name, 'models', 'results.npy'), results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### p1_learning_curve.jpg: learning curve\n",
    "results = np.load(os.path.join('/data/put_data/cclin/ntu/dlcv2018/hw5/results', dir_name, 'models', 'results.npy'))\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.plot(range(len(results[1])), results[1], label='Validation error')\n",
    "ax.plot(range(len(results[0])), results[0], label='Training error')\n",
    "ax.set_xticks(np.arange(len(results[0])))\n",
    "ax.set_xlabel('Training epochs', fontsize=16)\n",
    "ax.set_ylabel('Cross entropy', fontsize=16)\n",
    "ax.set_title('Learning Curve', fontsize=20)\n",
    "ax.legend(fontsize=16)\n",
    "fig.savefig(os.path.join('/data/put_data/cclin/ntu/dlcv2018/hw5/results', dir_name, 'p1_learning_curve.jpg'))\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: the output path \"/data/put_data/cclin/ntu/dlcv2018/hw5/results/cnn_dnn_2048_512_11_bs32_lr5e5_ep50\" already exists!\n",
      "INFO:tensorflow:Restoring parameters from /data/put_data/cclin/ntu/dlcv2018/hw5/results/cnn_dnn_2048_512_11_bs32_lr5e5_ep50/models/cnn_dnn_2048_512_11_bs32_lr5e5_ep50.model-5\n",
      " [*] Success to read cnn_dnn_2048_512_11_bs32_lr5e5_ep50.model-5\n",
      " [*] Load SUCCESS\n",
      "valid loss: 1.588220, valid accuracy: 0.461029\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    net = DNN(sess,\n",
    "              model_name=dir_name)\n",
    "    net.build_model()\n",
    "    net.inference(feature_path=feature_path_valid,\n",
    "                  label_file=label_file_valid,\n",
    "                  gen_from=os.path.join('/data/put_data/cclin/ntu/dlcv2018/hw5/results', dir_name, 'models'),\n",
    "                  out_path=os.path.join('/data/put_data/cclin/ntu/dlcv2018/hw5/results', dir_name),\n",
    "                  bsize=bsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debug: statistics of number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.367504835589942\n",
      "5.0\n",
      "17.749066179769716\n"
     ]
    }
   ],
   "source": [
    "res = np.load(feature_path_valid)\n",
    "\n",
    "n_frames_valid = [r.shape[0] for r in res]\n",
    "print(np.mean(n_frames_valid))\n",
    "print(np.median(n_frames_valid))\n",
    "print(np.std(n_frames_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05029013539651837"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i > 30 for i in n_frames_valid]) / len(n_frames_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.193757725587144\n",
      "5.0\n",
      "13.51620272358004\n"
     ]
    }
   ],
   "source": [
    "res = np.load(feature_path_train)\n",
    "\n",
    "n_frames_train = [r.shape[0] for r in res]\n",
    "print(np.mean(n_frames_train))\n",
    "print(np.median(n_frames_train))\n",
    "print(np.std(n_frames_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061495673671199014"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i > 30 for i in n_frames_train]) / len(n_frames_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
