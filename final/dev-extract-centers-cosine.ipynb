{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='6'\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from VGG16_GAP import VGG16_GAP\n",
    "# from VGG16_flatten import VGG16_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as imageio\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from progress.bar import Bar\n",
    "# from ipywidgets import IntProgress\n",
    "# from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/cclin/ntu/dlcv2018/DLCV2018SPRING/final/label_dict.pkl', 'rb') as f:\n",
    "    y_dict = pickle.load(f)\n",
    "\n",
    "with open('/home/cclin/ntu/dlcv2018/DLCV2018SPRING/final/inv_label_dict.pkl', 'rb') as f:\n",
    "    inv_y_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('save/inv_label_dict.pkl', 'rb') as f:\n",
    "#     inv_y_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOME_DIR = \"/data/put_data/cclin/ntu/dlcv2018/final/\"\n",
    "TRAIN_DIR = HOME_DIR+\"dlcv_final_2_dataset/train/\"\n",
    "VALID_DIR = HOME_DIR+\"dlcv_final_2_dataset/val/\"\n",
    "TEST_DIR = HOME_DIR+\"dlcv_final_2_dataset/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = pd.read_csv(HOME_DIR+\"dlcv_final_2_dataset/train_id.txt\", header=None,sep=\" \", names=[\"img\", \"id\"])\n",
    "dvalid = pd.read_csv(HOME_DIR+\"dlcv_final_2_dataset/val_id.txt\", header=None,sep=\" \", names=[\"img\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list = list(TRAIN_DIR+dtrain.img)\n",
    "valid_list = list(VALID_DIR+dvalid.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_list = list()\n",
    "for root, subdir, files in os.walk(TEST_DIR):\n",
    "    for file in sorted(files):\n",
    "        if '.jpg' in file:\n",
    "            test_list.append(os.path.join(TEST_DIR, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readImgList(file_list):\n",
    "    images = list()\n",
    "    for i, file in enumerate(file_list):\n",
    "        print(i, end=\"\\r\")\n",
    "        img = imageio.imread(file)\n",
    "        img = img.astype(int)\n",
    "        images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformLabel(id_list, y_dict):\n",
    "    label = list()\n",
    "    for uid in list(id_list):\n",
    "        label.append(y_dict[uid])\n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(class_numbers, num_classes):\n",
    "    return np.eye(num_classes, dtype=float)[class_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v,f) in zip(global_vars, is_not_initialized) if not f]\n",
    "    if len(not_initialized_vars): \n",
    "            sess.run(tf.variables_initializer(not_initialized_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (56475, 218, 178, 3)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = readImgList(train_list)\n",
    "print(\"train:\", Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: (7211, 218, 178, 3)\n"
     ]
    }
   ],
   "source": [
    "Xvalid = readImgList(valid_list)\n",
    "print(\"valid:\", Xvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: (7152, 218, 178, 3)\n"
     ]
    }
   ],
   "source": [
    "Xtest = readImgList(test_list)\n",
    "print(\"valid:\", Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain = transformLabel(list(dtrain.id), y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yvalid = transformLabel(list(dvalid.id), y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ytrain = one_hot_encoding(ytrain, len(y_dict))\n",
    "Yvalid = one_hot_encoding(yvalid, len(y_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scope_name = \"Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VGG16_GAP(scope_name=scope_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAG_save_dir = \"/data/put_data/cmchang/DLCV_final/CL_v3-cont2_dynamic_gap_L5_v3_rescale0-1_save_linear/\"\n",
    "FLAG_init_from = FLAG_save_dir + \"para_dict.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build model started\n",
      "npy file loaded\n",
      "build model finished: 0s\n"
     ]
    }
   ],
   "source": [
    "model.build(vgg16_npy_path=FLAG_init_from,\n",
    "            shape=Xtrain.shape[1:],\n",
    "            classes=len(y_dict),\n",
    "            conv_pre_training=True,\n",
    "            fc_pre_training=True,\n",
    "            new_bn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP under test: [1.]\n",
      "[None, 218, 178, 3]\n",
      "[None, 218, 178, 32]\n",
      "AFTER [None, 218, 178, 32]\n",
      "[None, 109, 89, 47]\n",
      "AFTER [None, 109, 89, 47]\n",
      "[None, 109, 89, 63]\n",
      "AFTER [None, 109, 89, 63]\n",
      "[None, 55, 45, 98]\n",
      "AFTER [None, 55, 45, 98]\n",
      "[None, 55, 45, 134]\n",
      "AFTER [None, 55, 45, 134]\n",
      "[None, 55, 45, 147]\n",
      "AFTER [None, 55, 45, 147]\n",
      "[None, 28, 23, 153]\n",
      "AFTER [None, 28, 23, 153]\n",
      "[None, 28, 23, 209]\n",
      "AFTER [None, 28, 23, 209]\n",
      "[None, 28, 23, 181]\n",
      "AFTER [None, 28, 23, 181]\n",
      "[None, 14, 12, 177]\n",
      "AFTER [None, 14, 12, 177]\n",
      "[None, 14, 12, 180]\n",
      "AFTER [None, 14, 12, 180]\n",
      "[None, 14, 12, 230]\n",
      "AFTER [None, 14, 12, 230]\n",
      "Set dp operations finished: 0s\n"
     ]
    }
   ],
   "source": [
    "dp = [1.0]\n",
    "model.set_idp_operation(dp=dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def count_number_params(para_dict):\n",
    "#     n = 0\n",
    "#     for k,v in sorted(para_dict.items()):\n",
    "#         if 'bn_mean' in k:\n",
    "#             continue\n",
    "#         elif 'bn_variance' in k:\n",
    "#             continue\n",
    "#         elif 'gamma' in k:\n",
    "#             continue\n",
    "#         elif 'beta' in k:\n",
    "#             continue\n",
    "#         elif 'conv' in k or 'fc' in k:\n",
    "#             n += get_params_shape(v[0].shape.as_list())\n",
    "#             n += get_params_shape(v[1].shape.as_list())\n",
    "#     return n\n",
    "\n",
    "# def get_params_shape(shape):\n",
    "#     n = 1\n",
    "#     for dim in shape:\n",
    "#         n = n*dim\n",
    "#     return n\n",
    "\n",
    "# def count_flops(para_dict, net_shape):\n",
    "#     input_shape = (3 ,32 ,32) # Format:(channels, rows,cols)\n",
    "#     total_flops_per_layer = 0\n",
    "#     input_count = 0\n",
    "#     for k,v in sorted(para_dict.items()):\n",
    "#         if 'bn_mean' in k:\n",
    "#             continue\n",
    "#         elif 'bn_variance' in k:\n",
    "#             continue\n",
    "#         elif 'gamma' in k:\n",
    "#             continue\n",
    "#         elif 'beta' in k:\n",
    "#             continue\n",
    "#         elif 'fc' in k:\n",
    "#             continue\n",
    "#         elif 'conv' in k:\n",
    "#             conv_filter = v[0].shape.as_list()[3::-1] # (64 ,3 ,3 ,3)  # Format: (num_filters, channels, rows, cols)\n",
    "#             stride = 1\n",
    "#             padding = 1\n",
    "\n",
    "#             if conv_filter[1] == 0:\n",
    "#                 n = conv_filter[2] * conv_filter[3] # vector_length\n",
    "#             else:\n",
    "#                 n = conv_filter[1] * conv_filter[2] * conv_filter[3]  # vector_length\n",
    "\n",
    "#             flops_per_instance = n + ( n -1)    # general defination for number of flops (n: multiplications and n-1: additions)\n",
    "\n",
    "#             num_instances_per_filter = (( input_shape[1] - conv_filter[2] + 2 * padding) / stride) + 1  # for rows\n",
    "#             num_instances_per_filter *= ((input_shape[1] - conv_filter[2] + 2 * padding) / stride) + 1  # multiplying with cols\n",
    "\n",
    "#             flops_per_filter = num_instances_per_filter * flops_per_instance\n",
    "#             total_flops_per_layer += flops_per_filter * conv_filter[0]  # multiply with number of filters\n",
    "\n",
    "#             total_flops_per_layer += conv_filter[0] * input_shape[1] * input_shape[2]\n",
    "\n",
    "#             input_shape = net_shape[input_count].as_list()[3:0:-1]\n",
    "#             input_count +=1\n",
    "\n",
    "#     total_flops_per_layer += net_shape[-1].as_list()[1] *2360*2\n",
    "#     return total_flops_per_layer\n",
    "\n",
    "# def countFlopsParas(net):\n",
    "#     total_flops = count_flops(net.para_dict, net.net_shape)\n",
    "#     if total_flops / 1e9 > 1:   # for Giga Flops\n",
    "#         print(total_flops/ 1e9 ,'{}'.format('GFlops'))\n",
    "#     else:\n",
    "#         print(total_flops / 1e6 ,'{}'.format('MFlops'))\n",
    "\n",
    "#     total_params = count_number_params(net.para_dict)\n",
    "\n",
    "#     if total_params / 1e9 > 1:   # for Giga Flops\n",
    "#         print(total_params/ 1e9 ,'{}'.format('G'))\n",
    "#     else:\n",
    "#         print(total_params / 1e6 ,'{}'.format('M'))\n",
    "    \n",
    "#     return total_flops, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_number_params(para_dict):\n",
    "    n = 0\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            continue\n",
    "        elif 'bn_variance' in k:\n",
    "            continue\n",
    "        elif 'gamma' in k:\n",
    "            continue\n",
    "        elif 'beta' in k:\n",
    "            continue\n",
    "        elif 'conv' in k or 'fc' in k:\n",
    "            n += get_params_shape(v[0].shape.as_list())\n",
    "            n += get_params_shape(v[1].shape.as_list())\n",
    "    return n\n",
    "\n",
    "def get_params_shape(shape):\n",
    "    n = 1\n",
    "    for dim in shape:\n",
    "        n = n*dim\n",
    "    return n\n",
    "\n",
    "def count_flops(para_dict, net_shape, input_shape=(3, 218, 178)):\n",
    "    # Format:(channels, rows,cols)\n",
    "    total_flops_per_layer = 0\n",
    "    input_count = 0\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            continue\n",
    "        elif 'bn_variance' in k:\n",
    "            continue\n",
    "        elif 'gamma' in k:\n",
    "            continue\n",
    "        elif 'beta' in k:\n",
    "            continue\n",
    "        elif 'fc' in k:\n",
    "            continue\n",
    "        elif 'conv' in k:\n",
    "            conv_filter = v[0].shape.as_list()[3::-1] # (64 ,3 ,3 ,3)  # Format: (num_filters, channels, rows, cols)\n",
    "            stride = 1\n",
    "            padding = 1\n",
    "\n",
    "            if conv_filter[1] == 0:\n",
    "                n = conv_filter[2] * conv_filter[3] # vector_length\n",
    "            else:\n",
    "                n = conv_filter[1] * conv_filter[2] * conv_filter[3]  # vector_length\n",
    "\n",
    "            flops_per_instance = n + ( n -1)    # general defination for number of flops (n: multiplications and n-1: additions)\n",
    "\n",
    "            num_instances_per_filter = (( input_shape[1] - conv_filter[2] + 2 * padding) / stride) + 1  # for rows\n",
    "            num_instances_per_filter *= ((input_shape[2] - conv_filter[3] + 2 * padding) / stride) + 1  # multiplying with cols\n",
    "\n",
    "            flops_per_filter = num_instances_per_filter * flops_per_instance\n",
    "            total_flops_per_layer += flops_per_filter * conv_filter[0]  # multiply with number of filters\n",
    "\n",
    "            total_flops_per_layer += conv_filter[0] * input_shape[1] * input_shape[2] # bias\n",
    "\n",
    "            input_shape = net_shape[input_count].as_list()[3:0:-1]\n",
    "            input_count +=1\n",
    "\n",
    "    total_flops_per_layer += net_shape[-1].as_list()[1] *2360*2\n",
    "    return total_flops_per_layer\n",
    "\n",
    "def countFlopsParas(net):\n",
    "    total_flops = count_flops(net.para_dict, net.net_shape)\n",
    "    if total_flops / 1e9 > 1:   # for Giga Flops\n",
    "        print(total_flops/ 1e9 ,'{}'.format('GFlops'))\n",
    "    else:\n",
    "        print(total_flops / 1e6 ,'{}'.format('MFlops'))\n",
    "\n",
    "    total_params = count_number_params(net.para_dict)\n",
    "\n",
    "    if total_params / 1e9 > 1:   # for Giga Flops\n",
    "        print(total_params/ 1e9 ,'{}'.format('G'))\n",
    "    else:\n",
    "        print(total_params / 1e6 ,'{}'.format('M'))\n",
    "    \n",
    "    return total_flops, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.875544996 GFlops\n",
      "4.048755 M\n",
      "Flops: 6875.544996 M, Paras: 4.048755 M\n"
     ]
    }
   ],
   "source": [
    "flops, params = countFlopsParas(model)\n",
    "FLAG_flops_M = flops/1e6\n",
    "FLAG_params_M = params/1e6\n",
    "print(\"Flops: %3f M, Paras: %3f M\" % (flops/1e6, params/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "282\n",
      "36\n",
      "35\r"
     ]
    }
   ],
   "source": [
    "# extract features\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.global_variables())\n",
    "    print(\"Initialized\")\n",
    "    output_train = []\n",
    "    output_valid = []\n",
    "    output_test = []\n",
    "    for i in range(int(Xtrain.shape[0]/200+1)):\n",
    "        print(i, end=\"\\r\")\n",
    "        st = i*200\n",
    "        ed = min((i+1)*200, Xtrain.shape[0])\n",
    "        prob = sess.run(model.features, feed_dict={model.x: Xtrain[st:ed,:], \n",
    "                                                    model.is_train: False})\n",
    "        output_train.append(prob)\n",
    "    print()\n",
    "    \n",
    "    for i in range(int(Xvalid.shape[0]/200+1)):\n",
    "        print(i, end=\"\\r\")\n",
    "        st = i*200\n",
    "        ed = min((i+1)*200, Xvalid.shape[0])\n",
    "        prob = sess.run(model.features, feed_dict={model.x: Xvalid[st:ed,:], \n",
    "                                                    model.is_train: False})\n",
    "        output_valid.append(prob)\n",
    "    print()\n",
    "    \n",
    "    for i in range(int(Xtest.shape[0]/200+1)):\n",
    "        print(i, end=\"\\r\")\n",
    "        st = i*200\n",
    "        ed = min((i+1)*200, Xtest.shape[0])\n",
    "        prob = sess.run(model.features, feed_dict={model.x: Xtest[st:ed,:], \n",
    "                                                    model.is_train: False})\n",
    "        output_test.append(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute center and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'data', 'put_data', 'cmchang', 'DLCV_final', 'CL_v3-cont2_dynamic_gap_L5_v3_rescale0-1_save_linear', '']\n",
      "CL_v3-cont2_dynamic_gap_L5_v3_rescale0-1_save_linear\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "\n",
    "print(re.split(pattern='\\/', string=FLAG_save_dir))\n",
    "basic_model_name = re.split(pattern='\\/', string=FLAG_save_dir)[-2]\n",
    "print(basic_model_name)\n",
    "\n",
    "saved_path = os.path.join('/data/put_data/cclin/ntu/dlcv2018/final/results', basic_model_name)\n",
    "if not os.path.exists(saved_path):\n",
    "    os.makedirs(saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56475, 423)\n"
     ]
    }
   ],
   "source": [
    "EX_train = np.concatenate(output_train,)\n",
    "print(EX_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7211, 423)\n"
     ]
    }
   ],
   "source": [
    "EX_valid = np.concatenate(output_valid,)\n",
    "print(EX_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7152, 423)\n"
     ]
    }
   ],
   "source": [
    "EX_test = np.concatenate(output_test,)\n",
    "print(EX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(os.path.join(saved_path, 'EX_train.npy'), EX_train)\n",
    "np.save(os.path.join(saved_path, 'EX_valid.npy'), EX_valid)\n",
    "np.save(os.path.join(saved_path, 'EX_test.npy'), EX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers = np.zeros((len(y_dict), EX_train.shape[1]))\n",
    "for i in range(len(y_dict)):\n",
    "    centers[i,:] = np.mean(EX_train[ytrain==i,:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2360, 423)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(arr=centers,file=FLAG_save_dir+\"centers.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7211, 2360)\n",
      "(7211,)\n"
     ]
    }
   ],
   "source": [
    "cos_sim = cosine_similarity(EX_valid, centers)\n",
    "print(cos_sim.shape)\n",
    "pred_valid = np.argmax(cos_sim, axis=1)\n",
    "print(pred_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7867147413673554"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(list(yvalid), list(pred_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63686, 423)\n"
     ]
    }
   ],
   "source": [
    "EX_all = np.concatenate((EX_train, EX_valid))\n",
    "print(EX_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63686,)\n"
     ]
    }
   ],
   "source": [
    "Y = np.concatenate([ytrain, yvalid])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers_all = np.zeros((len(y_dict), EX_all.shape[1]))\n",
    "for i in range(len(y_dict)):\n",
    "    centers_all[i,:] = np.mean(EX_all[Y==i,:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2360, 423)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7152, 2360)\n",
      "(7152,)\n"
     ]
    }
   ],
   "source": [
    "cos_sim = cosine_similarity(EX_test, centers_all)\n",
    "print(cos_sim.shape)\n",
    "pred_test = np.argmax(cos_sim, axis=1)\n",
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_id = list()\n",
    "for pred in pred_test:\n",
    "    final_id.append(inv_y_dict[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doutput = pd.DataFrame({'id':np.arange(len(final_id))+1, 'ans':final_id}, columns=['id','ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'data', 'put_data', 'cmchang', 'DLCV_final', 'CL_v3-cont2_dynamic_gap_L5_v3_rescale0-1_save_linear', '']\n",
      "CL_v3-cont2_dynamic_gap_L5_v3_rescale0-1_save_linear\n",
      "cos_pred_val78_CL_v3-cont2_dynamic_gap_L5_v3_rescale0-1_save_linear.csv\n"
     ]
    }
   ],
   "source": [
    "output_name = \"cos_pred_val78_\" + basic_model_name + \".csv\"\n",
    "print(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doutput.to_csv(output_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backup: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "# neigh.fit(centers, np.arange(len(y_dict)))\n",
    "# pred_valid = neigh.predict(EX_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### compute error for each class (use validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/function_base.py:1128: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class = []\n",
    "for i in range(len(y_dict)):\n",
    "    accuracy_per_class.append(accuracy_score(list(yvalid[yvalid==i]), list(pred_valid[yvalid==i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(ytrain))\n",
    "\n",
    "\n",
    "inv_y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
